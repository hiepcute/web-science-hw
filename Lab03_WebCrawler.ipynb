{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaqjihtwRrys"
   },
   "source": [
    "# Lab03: Web Crawler (Continue) & Information Retrieval.\n",
    "\n",
    "- MSSV: 1712429\n",
    "- Họ và tên:Đỗ Văn Hiệp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FUG7FFTsRryt"
   },
   "source": [
    "## Yêu cầu bài tập\n",
    "\n",
    "**Cách làm bài**\n",
    "\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này; từ `TODO` cho biết những phần mà bạn cần phải làm.\n",
    "\n",
    "Bạn có thể thảo luận ý tưởng cũng như tham khảo các tài liệu, nhưng *code và bài làm phải là của bạn*. \n",
    "\n",
    "Nếu vi phạm thì sẽ bị 0 điểm cho bài tập này.\n",
    "\n",
    "**Cách nộp bài**\n",
    "\n",
    "Trước khi nộp bài, rerun lại notebook (`Kernel` -> `Restart & Run All`).\n",
    "\n",
    "Sau đó, tạo thư mục có tên `MSSV` của bạn (vd, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`) Chép file notebook, file `t_data.txt` và file `raw_data` của các bạn (nếu file này kích thước lớn các bạn có thể chép link vào `link_data.txt`), nén thư mục `MSSV` này lại và nộp trên moodle.\n",
    "\n",
    "**Nội dung bài tập**\n",
    "\n",
    "Cài đặt một web crawler để thu thập dữ liệu từ: https://en.wikipedia.org/wiki/Web_mining."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HlhdT6BRryu"
   },
   "source": [
    "## Nội dung bài tập"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c9-ZyiLjRryv"
   },
   "source": [
    "Cài đặt một Web crawler đơn giản bắt đầu từ URL: https://en.wikipedia.org/wiki/Web_mining, tìm liên kết và thu thập dữ liệu trong HTML tại URL này sau đó lặp lại với các URL vừa tìm được.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FJktAwbCOyod"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Comment\n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mMSlOpSsRryv"
   },
   "source": [
    "## 1. Thu thập đường dẫn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZZ9lSUPRryw"
   },
   "source": [
    "- Robot.txt:  https://en.wikipedia.org/robots.txt\n",
    "- **Bước 1**: Thu thập đường dẫn từ https://en.wikipedia.org/wiki/Web_mining. Lưu trữ vào một danh sách `url_list`. \n",
    "- **Bước 2**: Lặp lại bước 1 cho các đường dẫn trong `url_list` (**lưu ý:** kiểm tra các đường dẫn vừa thu được đã nằm trong `url_list` hay không?). Dừng khi đã thu thập được 200 URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4HFWqw1VOrEe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Web_mining\n",
      "https://en.wikipedia.org/w/index.php?title=Web_mining&amp;action=edit\n",
      "https://en.wikipedia.org/w/index.php?title=Web_mining&amp;action=edit&amp;section=\n",
      "https://archive.org/details/webinformationsy00ngua\n",
      "https://archive.org/details/webinformationsy00ngua/page/n33\n",
      "https://archive.org/details/electroniccommer00bauk_698\n",
      "https://archive.org/details/electroniccommer00bauk_698/page/n176\n",
      "https://archive.org/details/webminingapplica0000scim/page/282\n",
      "http://alexandria.tue.nl/repository/freearticles/612259.pdf\n",
      "http://www.cis.unisa.edu.au/\n",
      "https://docs.google.com/open?id=1nU1vrz-gBtSJk3bkb1ls_QuGX2nUPPemECPFlCx0C75MvmQdSqPci6LZWJYf\n",
      "https://ui.adsabs.harvard.edu/abs/2000cs.......11033K\n",
      "https://doi.org/10.1145%2F360402.360406\n",
      "https://api.semanticscholar.org/CorpusID:60455\n",
      "http://library.ifla.org/148/\n",
      "https://doi.org/10.5195%2Fjmla.2019.650\n",
      "http://soave.isti.cnr.it/%7Esilvestr/wp-content/uploads/2007/03/p63-baraglia.pdf\n",
      "http://facweb.cs.depaul.edu/mobasher/classes/ect584/papers/cms-kais.pdf\n",
      "https://link.springer.com/chapter/10.1007/978-3-540-88309-8_34\n",
      "http://robotics.stanford.edu/\n",
      "http://informationr.net/ir/11-2/paper249.html\n",
      "https://www.researchgate.net/profile/Magdalini_Eirinaki/publication/220169917_Web_mining_for_web_personalization/links/0912f51379b8daa82a000000.pdf\n",
      "http://dmr.cs.umn.edu/Papers/P2000_10.pdf\n",
      "http://facweb.cs.depaul.edu/mobasher/research/papers/widm01.pdf\n",
      "http://webmining.spd.louisville.edu/wp-content/uploads/2014/05/Nasraoui_WebKDD03_web_recomm.pdf\n",
      "http://webmining.spd.louisville.edu/wp-content/uploads/2014/05/Nasraoui-IFSA-99-mining-web-access-logs.pdf\n",
      "http://webmining.spd.louisville.edu/wp-content/uploads/2014/05/FINAL-Nasraoui-WWW-Personalization.pdf\n",
      "http://www.chris-kimble.com/Publications/Documents/Ting_2005b.pdf\n",
      "http://csdl2.computer.org/persagen/DLAbsToc.jsp?resourcePath=/dl/proceedings/wi/&amp;toc=comp/proceedings/wi/2005/2415/00/2415toc.xml&amp;DOI=10.1109/WI.2005.153\n",
      "https://www.researchgate.net/publication/230852676_Web_User_Navigation_Patterns_Discovery_from_WWW_Server_Log_Files/file/9fcfd5055ba8960606.pdf\n",
      "https://doi.org/10.1007/3-540-48298-9_32\n",
      "https://doi.org/10.1007/3-540-48298-9_32</a>.</li></ul>\n",
      "https://en.wikipedia.org/w/index.php?title=Web_mining&amp;oldid=1014859181\n",
      "https://en.wikipedia.org/w/index.php?title=Web_mining&amp;oldid=1014859181</a>\n",
      "https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en\n",
      "https://www.wikidata.org/wiki/Special:EntityPage/Q785337\n",
      "https://ar.wikipedia.org/wiki/%D8%AA%D9%86%D9%82%D9%8A%D8%A8_%D8%A7%D9%84%D9%88%D9%8A%D8%A8\n",
      "https://de.wikipedia.org/wiki/Web_Mining\n",
      "https://es.wikipedia.org/wiki/Web_mining\n",
      "https://eu.wikipedia.org/wiki/Web-meatzaritza\n",
      "https://fa.wikipedia.org/wiki/%D9%88%D8%A8%E2%80%8C%DA%A9%D8%A7%D9%88%DB%8C\n",
      "https://fr.wikipedia.org/wiki/Fouille_du_web\n",
      "https://ko.wikipedia.org/wiki/%EC%9B%B9_%EB%A7%88%EC%9D%B4%EB%8B%9D\n",
      "https://hi.wikipedia.org/wiki/%E0%A4%85%E0%A4%82%E0%A4%A4%E0%A4%B0%E0%A4%9C%E0%A4%BE%E0%A4%B2_%E0%A4%96%E0%A4%A8%E0%A4%A8\n",
      "https://hr.wikipedia.org/wiki/Dubinsko_pretra%C5%BEivanje_interneta\n",
      "https://hu.wikipedia.org/wiki/Webb%C3%A1ny%C3%A1szat\n",
      "https://ja.wikipedia.org/wiki/%E3%82%A6%E3%82%A7%E3%83%96%E3%83%9E%E3%82%A4%E3%83%8B%E3%83%B3%E3%82%B0\n",
      "https://pt.wikipedia.org/wiki/Minera%C3%A7%C3%A3o_da_web\n",
      "https://ru.wikipedia.org/wiki/Web_mining\n",
      "https://sk.wikipedia.org/wiki/Web_mining\n",
      "https://th.wikipedia.org/wiki/%E0%B8%81%E0%B8%B2%E0%B8%A3%E0%B8%97%E0%B8%B3%E0%B9%80%E0%B8%AB%E0%B8%A1%E0%B8%B7%E0%B8%AD%E0%B8%87%E0%B9%80%E0%B8%A7%E0%B9%87%E0%B8%9A\n",
      "https://foundation.wikimedia.org/wiki/Privacy_policy\n",
      "https://www.mediawiki.org/wiki/Special:MyLanguage/How_to_contribute\n",
      "https://stats.wikimedia.org/\n",
      "https://foundation.wikimedia.org/wiki/Cookie_statement\n",
      "https://wikimediafoundation.org/\n",
      "https://www.mediawiki.org/\n",
      "http://www.gnu.org/licenses/>.\n",
      "https://archive.org/services/img/webinformationsy00ngua\n",
      "https://archive.org/services/img/webinformationsy00ngua/full/pct:200/0/default.jpg\n",
      "https://archive.org/images/glogo.jpg\n",
      "http://schema.org/Book\n",
      "http://blog.archive.org/2020/06/10/temporary-national-emergency-library-to-close-2-weeks-early-returning-to-traditional-controlled-digital-lending/\n",
      "https://archive.org\n",
      "http://www.w3.org/2000/svg\n",
      "https://archive.org/search.php\n",
      "https://archive.org/create/\n",
      "https://archive.org/account/signup\n",
      "https://archive.org/account/login\n",
      "https://archive.org/web/\n",
      "https://archive.org/details/texts\n",
      "https://archive.org/details/movies\n",
      "https://archive.org/details/audio\n",
      "https://archive.org/details/software\n",
      "https://archive.org/details/image\n",
      "https://archive.org/donate/\n",
      "https://archive.org/about/\n",
      "https://blog.archive.org/\n",
      "https://archive.org/projects/\n",
      "https://archive.org/about/faqs.php\n",
      "https://archive.org/about/contact.php\n",
      "https://archive.org/about/jobs.php\n",
      "https://archive.org/about/volunteerpositions.php\n",
      "https://archive.org/about/bios.php\n",
      "https://archive.org/advancedsearch.php\n",
      "https://twitter.com/intent/tweet?url=https://archive.org/details/webinformationsy00ngua&amp;via=internetarchive&amp;text=Web+information+systems+engineering+%3A+WISE+2005%2C+6th+International+Conference+on+Web+Information+Systems+Engineering%2C+New+York%2C+NY%2C+USA%2C+November+20-22%2C+2005+%3A+proceedings+%3A+International+Conference+on+Web+Information+Systems+Engineering+%286th+%3A+2005+%3A+New+York%2C+N.Y.%29+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.facebook.com/sharer/sharer.php?u=https://archive.org/details/webinformationsy00ngua\n",
      "http://www.reddit.com/submit?url=https://archive.org/details/webinformationsy00ngua&amp;title=Web+information+systems+engineering+%3A+WISE+2005%2C+6th+International+Conference+on+Web+Information+Systems+Engineering%2C+New+York%2C+NY%2C+USA%2C+November+20-22%2C+2005+%3A+proceedings+%3A+International+Conference+on+Web+Information+Systems+Engineering+%286th+%3A+2005+%3A+New+York%2C+N.Y.%29+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.tumblr.com/share/video?embed=%3Ciframe+width%3D%22640%22+height%3D%22480%22+frameborder%3D%220%22+allowfullscreen+src%3D%22https%3A%2F%2Farchive.org%2Fembed%2F%22+webkitallowfullscreen%3D%22true%22+mozallowfullscreen%3D%22true%22%26gt%3B%26lt%3B%2Fiframe%3E&amp;name=Web+information+systems+engineering+%3A+WISE+2005%2C+6th+International+Conference+on+Web+Information+Systems+Engineering%2C+New+York%2C+NY%2C+USA%2C+November+20-22%2C+2005+%3A+proceedings+%3A+International+Conference+on+Web+Information+Systems+Engineering+%286th+%3A+2005+%3A+New+York%2C+N.Y.%29+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "http://www.pinterest.com/pin/create/button/?url=https://archive.org/details/webinformationsy00ngua&amp;description=Web+information+systems+engineering+%3A+WISE+2005%2C+6th+International+Conference+on+Web+Information+Systems+Engineering%2C+New+York%2C+NY%2C+USA%2C+November+20-22%2C+2005+%3A+proceedings+%3A+International+Conference+on+Web+Information+Systems+Engineering+%286th+%3A+2005+%3A+New+York%2C+N.Y.%29+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://archive.org/details/webinformationsy00ngua&amp;subject=Web\n",
      "https://archive.org/embed/webinformationsy00ngua\n",
      "https://openlibrary.org/books/OL9056073M\n",
      "https://openlibrary.org/works/OL16933587W\n",
      "https://www.worldcat.org/oclc/150395224\n",
      "http://schema.org/InteractionCounter\n",
      "http://schema.org/ViewAction\n",
      "https://archive.org/services/img/electroniccommer00bauk_698\n",
      "https://archive.org/services/img/electroniccommer00bauk_698/full/pct:200/0/default.jpg\n",
      "https://twitter.com/intent/tweet?url=https://archive.org/details/electroniccommer00bauk_698&amp;via=internetarchive&amp;text=Electronic+commerce+and+web+technologies+%3A+first+international+conference%2C+EC-Web+2000%2C+London%2C+UK%2C+September+4-6%2C+2000+proceedings+%3A+Bauknecht%2C+Kurt%2C+1936-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.facebook.com/sharer/sharer.php?u=https://archive.org/details/electroniccommer00bauk_698\n",
      "http://www.reddit.com/submit?url=https://archive.org/details/electroniccommer00bauk_698&amp;title=Electronic+commerce+and+web+technologies+%3A+first+international+conference%2C+EC-Web+2000%2C+London%2C+UK%2C+September+4-6%2C+2000+proceedings+%3A+Bauknecht%2C+Kurt%2C+1936-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.tumblr.com/share/video?embed=%3Ciframe+width%3D%22640%22+height%3D%22480%22+frameborder%3D%220%22+allowfullscreen+src%3D%22https%3A%2F%2Farchive.org%2Fembed%2F%22+webkitallowfullscreen%3D%22true%22+mozallowfullscreen%3D%22true%22%26gt%3B%26lt%3B%2Fiframe%3E&amp;name=Electronic+commerce+and+web+technologies+%3A+first+international+conference%2C+EC-Web+2000%2C+London%2C+UK%2C+September+4-6%2C+2000+proceedings+%3A+Bauknecht%2C+Kurt%2C+1936-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "http://www.pinterest.com/pin/create/button/?url=https://archive.org/details/electroniccommer00bauk_698&amp;description=Electronic+commerce+and+web+technologies+%3A+first+international+conference%2C+EC-Web+2000%2C+London%2C+UK%2C+September+4-6%2C+2000+proceedings+%3A+Bauknecht%2C+Kurt%2C+1936-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://archive.org/details/electroniccommer00bauk_698&amp;subject=Electronic\n",
      "https://archive.org/embed/electroniccommer00bauk_698\n",
      "https://openlibrary.org/books/OL9063486M\n",
      "https://openlibrary.org/works/OL16991518W\n",
      "https://www.worldcat.org/oclc/247451473\n",
      "https://www.betterworldbooks.com/product/detail/electronic-commerce-and-web-technologies-first-international-conference-ec-web-2000-london-uk-3540679812\n",
      "https://archive.org/services/img/webminingapplica0000scim\n",
      "https://archive.org/details/webminingapplica0000scim\n",
      "https://archive.org/services/img/webminingapplica0000scim/full/pct:200/0/default.jpg\n",
      "https://twitter.com/intent/tweet?url=https://archive.org/details/webminingapplica0000scim&amp;via=internetarchive&amp;text=Web+mining+%3A+applications+and+techniques+%3A+Scime%2C+Anthony%2C+1952-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.facebook.com/sharer/sharer.php?u=https://archive.org/details/webminingapplica0000scim\n",
      "http://www.reddit.com/submit?url=https://archive.org/details/webminingapplica0000scim&amp;title=Web+mining+%3A+applications+and+techniques+%3A+Scime%2C+Anthony%2C+1952-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.tumblr.com/share/video?embed=%3Ciframe+width%3D%22640%22+height%3D%22480%22+frameborder%3D%220%22+allowfullscreen+src%3D%22https%3A%2F%2Farchive.org%2Fembed%2F%22+webkitallowfullscreen%3D%22true%22+mozallowfullscreen%3D%22true%22%26gt%3B%26lt%3B%2Fiframe%3E&amp;name=Web+mining+%3A+applications+and+techniques+%3A+Scime%2C+Anthony%2C+1952-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "http://www.pinterest.com/pin/create/button/?url=https://archive.org/details/webminingapplica0000scim&amp;description=Web+mining+%3A+applications+and+techniques+%3A+Scime%2C+Anthony%2C+1952-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://archive.org/details/webminingapplica0000scim&amp;subject=Web\n",
      "https://archive.org/embed/webminingapplica0000scim\n",
      "https://www.worldcat.org/oclc/56751163\n",
      "https://openlibrary.org/books/OL8854828M\n",
      "https://openlibrary.org/works/OL8980477W\n",
      "http://schema.org/BorrowAction\n",
      "http://www.w3.org/1999/02/22-rdf-syntax-ns\n",
      "http://ns.adobe.com/iX/1.0/'>\n",
      "http://ns.adobe.com/pdf/1.3/'\n",
      "http://ns.adobe.com/pdf/1.3/'>\n",
      "http://ns.adobe.com/xap/1.0/'\n",
      "http://ns.adobe.com/xap/1.0/'>\n",
      "http://www.w3.org/1999/xhtml\n",
      "http://ogp.me/ns\n",
      "https://www.facebook.com/2008/fbml\n",
      "https://unisa.edu.au/\n",
      "https://www.googletagmanager.com/gtm.js?id='+i+dl+\n",
      "https://cdnjs.cloudflare.com/ajax/libs/svg4everybody/2.1.9/svg4everybody.min.js\n",
      "https://www.googletagmanager.com/ns.html?id=GTM-KWN9ZR&gtm_auth=oqp3IO9yMdC3zYbtbyzyNg&gtm_preview=env-2&gtm_cookies_win=x\n",
      "https://study.unisa.edu.au/'\n",
      "https://study.unisa.edu.au/apply/\n",
      "http://study.unisa.edu.au/enquire\n",
      "https://study.unisa.edu.au/\n",
      "https://study.unisa.edu.au/study-with-us/entry-pathways/\n",
      "http://i.unisa.edu.au/students/scholarships/\n",
      "http://i.unisa.edu.au/students/student-support-services/student-accommodation/\n",
      "https://online.unisa.edu.au/\n",
      "http://international.unisa.edu.au/\n",
      "http://international.unisa.edu.au/what-can-i-study/\n",
      "http://international.unisa.edu.au/pre-entry-and-pathway-programs/\n",
      "https://study.unisa.edu.au/short-courses/\n",
      "http://i.unisa.edu.au/students/experience-unisa/\n",
      "http://i.unisa.edu.au/students/newstudents/\n",
      "https://study.unisa.edu.au/student-placements-and-internships/\n",
      "http://i.unisa.edu.au/students/student-support-services/\n",
      "https://unisasport.edu.au/\n",
      "http://i.unisa.edu.au/students/student-support-services/wirringka-student-services/\n",
      "http://fii.unisa.edu.au/\n",
      "https://www.marketingscience.info/\n",
      "https://www.centreforcancerbiology.org.au/\n",
      "http://fii.unisa.edu.au/fia/\n",
      "http://icc.unisa.edu.au/\n",
      "https://www.unisaventures.com.au/\n",
      "http://giving.unisa.edu.au/\n",
      "https://study.unisa.edu.au/student-placements-and-internships/nursing-health-medical-sciences/cpu/\n",
      "http://www.library.unisa.edu.au/\n",
      "https://unisasport.edu.au/facilities\n",
      "http://i.unisa.edu.au/staff/facilities/security/\n",
      "http://i.unisa.edu.au/staff/ptc/resources/policies-procedures-and-guidelines/\n",
      "http://workingatunisa.nga.net.au/\n",
      "https://my.unisa.edu.au/public/staffweb/\n",
      "http://i.unisa.edu.au/students/\n",
      "https://search.unisa.edu.au/s/search.html?collection=study-search&amp;f.Tabs\n",
      "http://www.w3.org/1999/xlink\n",
      "https://search.unisa.edu.au/s/search.html?collection=study-search&amp;f.Tabs%7Ctab=Degrees+%26+Courses\n",
      "https://study.unisa.edu.au/aboriginal-and-australian-studies/\n",
      "https://study.unisa.edu.au/accounting-and-finance/\n",
      "https://study.unisa.edu.au/architecture/\n",
      "https://study.unisa.edu.au/arts/\n",
      "https://study.unisa.edu.au/arts-and-cultural-management/\n",
      "https://study.unisa.edu.au/aviation/\n",
      "https://study.unisa.edu.au/biomedical-sciences/\n",
      "https://study.unisa.edu.au/business/\n",
      "https://study.unisa.edu.au/communications-and-media/\n",
      "https://study.unisa.edu.au/construction-management/\n",
      "https://study.unisa.edu.au/contemporary-art/\n",
      "https://study.unisa.edu.au/creative-industries/\n",
      "https://study.unisa.edu.au/cybersecurity2/\n",
      "https://study.unisa.edu.au/data-science/\n",
      "https://study.unisa.edu.au/defence/\n",
      "https://study.unisa.edu.au/design/\n",
      "https://study.unisa.edu.au/education/\n",
      "https://study.unisa.edu.au/engineering/\n",
      "https://study.unisa.edu.au/environmental-science/\n",
      "https://study.unisa.edu.au/film-and-tv/\n",
      "https://study.unisa.edu.au/geospatial-science-and-surveying/\n",
      "https://study.unisa.edu.au/health-science/\n",
      "https://study.unisa.edu.au/human-movement-sport-clinical-exercise-physiology/\n",
      "https://study.unisa.edu.au/human-services/\n",
      "https://study.unisa.edu.au/information-management/\n",
      "https://study.unisa.edu.au/information-technology/\n",
      "https://study.unisa.edu.au/journalism-and-professional-writing/\n",
      "https://study.unisa.edu.au/laboratory-medicine/\n",
      "https://study.unisa.edu.au/languages/\n",
      "https://study.unisa.edu.au/law/\n",
      "https://study.unisa.edu.au/management/\n",
      "https://study.unisa.edu.au/marketing/\n",
      "https://study.unisa.edu.au/mathematics/\n",
      "https://study.unisa.edu.au/mba/\n",
      "https://study.unisa.edu.au/medical-radiation/\n",
      "https://study.unisa.edu.au/nursing-midwifery/\n",
      "https://study.unisa.edu.au/nutrition-food-sciences/\n",
      "https://study.unisa.edu.au/occupational-therapy/\n",
      "https://study.unisa.edu.au/pharmacy/\n",
      "https://study.unisa.edu.au/physiotherapy/\n",
      "https://study.unisa.edu.au/podiatry/\n",
      "https://study.unisa.edu.au/project-management/\n",
      "https://study.unisa.edu.au/property/\n",
      "https://study.unisa.edu.au/psychology/\n",
      "https://study.unisa.edu.au/science/\n",
      "https://study.unisa.edu.au/social-work/\n",
      "https://study.unisa.edu.au/speech-pathology/\n",
      "https://study.unisa.edu.au/surveying/\n",
      "https://study.unisa.edu.au/tourism-sport-and-events/\n",
      "https://study.unisa.edu.au/urban-and-regional-planning/\n",
      "https://study.unisa.edu.au/unisa-college/\n",
      "https://ask.australian.unisa.edu.au/\n",
      "https://ask.international.unisa.edu.au/\n",
      "http://international.unisa.edu.au/contact-us/\n",
      "https://askcampuscentral.unisa.edu.au/\n",
      "http://i.unisa.edu.au/campus-central/Contact-Us/\n",
      "https://study.unisa.edu.au/enquire/\n",
      "http://www.facebook.com/UniSA\n",
      "https://twitter.com/universitysa\n",
      "http://www.linkedin.com/company/10761\n",
      "http://www.youtube.com/unisouthaustralia\n",
      "http://instagram.com/universitysa\n",
      "http://i.unisa.edu.au/askit/\n",
      "http://www.atn.edu.au/\n",
      "http://southaustralia.com/\n",
      "https://cricos.education.gov.au/Institution/InstitutionDetails.aspx?ProviderID=121\n",
      "https://www.google.com/recaptcha/api.js?render=6LcFxr8ZAAAAAETUOEjH2U68-d9Zi5US-Ls7N4FY\n",
      "https://cdnjs.cloudflare.com/ajax/libs/mobile-detect/1.4.4/mobile-detect.min.js\n",
      "https://search.unisa.edu.au','unisa','_default','','345768','\n",
      "https://search.unisa.edu.au','unisa','_default','','383050','\n",
      "https://polyfill.io/v3/polyfill.min.js?flags=gated&amp;features=Object.assign%2CIntersectionObserver\n",
      "https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js\n"
     ]
    }
   ],
   "source": [
    "def get_urls(url):\n",
    "    r = requests.get(url)\n",
    "    # TODO\n",
    "    # Lấy các url nằm trong trang web của url này, lưu lại vào biến urls\n",
    "    urls = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', r.text)\n",
    "    urls_new=[]\n",
    "    for i in urls:\n",
    "        if (i not in urls_new):\n",
    "            urls_new.append(i)\n",
    "    return urls_new\n",
    "\n",
    "def get_urls_recursive(start_url, limit):\n",
    "    urls = [start_url]\n",
    "    for url in urls:\n",
    "        # TODO\n",
    "        # Lấy các url nằm trong trang web của url này, lưu lại vào biến new_urls\n",
    "        # Với mỗi url mới trong new_urls:\n",
    "        #   Nếu nó chưa nằm trong urls thì thêm nó vô  \n",
    "        # Nếu kích thước của urls vượt quá limit thì dừng và xóa phần dư thừa\n",
    "        new=get_urls(url)# lây  tất cả các url của trang web lưu vào biến new\n",
    "        for i in new: # kiểm tra các url trong new có nằm trong list urls hay ko\n",
    "            if i not in urls: # neeuw khong co\n",
    "                urls.append(i)\n",
    "        if len(urls)>200:\n",
    "            break\n",
    "    return urls\n",
    "url_list = get_urls_recursive('https://en.wikipedia.org/wiki/Web_mining', 200)\n",
    "for i in url_list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zk4ty3jcRryx"
   },
   "source": [
    "## 2. Thu thập dữ liệu\n",
    "Thu thập dữ liệu từ `url_list`. Lưu trữ dữ liệu thu được vào dictionary data với keys là các từ, values gồm 2 phần tử: \n",
    "- `url_idx_list` với $idx \\in \\left[0,200\\right) \\cap \\mathbb{N}$\n",
    "- `frequency` \n",
    "    \n",
    "Ví dụ: `data['at']=[url_idx_list,frequency]`:\n",
    "- `url_idx_list`: danh sách các url mà trong dữ liệu của chúng (html document) chứa từ \"at\". \n",
    "- `frequency`: tần suất xuất hiện (số lần xuất hiện) của từ `at` trong dữ liệu của **tất cả đường dẫn thu được**.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YB5nIZAhQr7-"
   },
   "outputs": [],
   "source": [
    "def text_filter(element):\n",
    "    if element.parent.name in ['style', 'title', 'script', 'head', '[document]', 'class', 'a', 'li']:\n",
    "        return False\n",
    "    elif isinstance(element, Comment):\n",
    "        '''Opinion mining?'''\n",
    "        return False\n",
    "    elif re.match(r\"[\\s\\r\\n]+\",str(element)): \n",
    "        '''space, return, endline'''\n",
    "        return False\n",
    "    return True\n",
    "def wordList(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    text = soup.findAll(text=True)\n",
    "    filtered_text = list(filter(text_filter, text)) # list của các chuỗi\n",
    "    word_list = []\n",
    "    \n",
    "    for i in range(0,len(filtered_text)):\n",
    "        if filtered_text[i] in string.punctuation:# kiểm tra xem có trong list kí tự hay không\n",
    "            filtered_text[i]= filtered_text[i].replace(filtered_text[i],\" \")#replace \" \" # thay thế bằng khoảng trắng\n",
    "    for i in range(0,len(filtered_text)):\n",
    "        list_w_split=[]\n",
    "        list_w_split=filtered_text[i].split(\" \")# tách các chuỗi thành các câu lưu vào word_list\n",
    "        for j in range(0,len(list_w_split)):\n",
    "            word_list.append(list_w_split[j])\n",
    "    for i in word_list:\n",
    "        if i in string.punctuation:# check word_list thêm một lần nữa, nếu có khoảng trắng thì remove\n",
    "            word_list.remove(i)\n",
    "    return word_list\n",
    "\n",
    "def read_url(url, url_idx, data):\n",
    "    word_list = wordList(url)\n",
    "    \n",
    "    # TODO\n",
    "    # Với mỗi từ w trong word_list:\n",
    "    #   Nếu w chưa có trong data thì khởi tạo data[w] = [[url_idx], 1]\n",
    "    #   Ngược lại thì thêm url_idx vào data[w][0] (nếu chưa có) và tăng data[w][1] lên 1 đơn vị\n",
    "    for i in range(0,len(word_list)) :\n",
    "        if word_list[i] not in data.keys():\n",
    "            data[word_list[i]]=[[url_idx],1]\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            #check url\n",
    "            if url_idx in data[word_list[i]][0]:\n",
    "                data[word_list[i]][0].append(i)\n",
    "                \n",
    "            data[word_list[i]][1]=data[word_list[i]][1]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LrPuiiDhQfrJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some characters could not be decoded, and were replaced with REPLACEMENT CHARACTER.\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "HTTPConnectionPool(host='soave.isti.cnr.it', port=80): Max retries exceeded with url: /~silvestr/wp-content/uploads/2007/03/p63-baraglia.pdf (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000026B77A499E8>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    158\u001b[0m             conn = connection.create_connection(\n\u001b[1;32m--> 159\u001b[1;33m                 (self._dns_host, self.port), self.timeout, **extra_kw)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merr\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    599\u001b[0m                                                   \u001b[0mbody\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 600\u001b[1;33m                                                   chunked=chunked)\n\u001b[0m\u001b[0;32m    601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    353\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m             \u001b[0mconn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mhttplib_request_kw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1228\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1229\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1230\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1274\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1275\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1015\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1016\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    955\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 956\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    957\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m         \u001b[0mconn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_conn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m             raise NewConnectionError(\n\u001b[1;32m--> 168\u001b[1;33m                 self, \"Failed to establish a new connection: %s\" % e)\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x0000026B77A499E8>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    448\u001b[0m                     \u001b[0mretries\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m                     \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m                 )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    637\u001b[0m             retries = retries.increment(method, url, error=e, _pool=self,\n\u001b[1;32m--> 638\u001b[1;33m                                         _stacktrace=sys.exc_info()[2])\n\u001b[0m\u001b[0;32m    639\u001b[0m             \u001b[0mretries\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\u001b[0m in \u001b[0;36mincrement\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    397\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='soave.isti.cnr.it', port=80): Max retries exceeded with url: /~silvestr/wp-content/uploads/2007/03/p63-baraglia.pdf (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000026B77A499E8>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-cdf9df6f1e2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;31m#read_url(url, url_index, data)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0murl_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mread_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-0234e178a6d1>\u001b[0m in \u001b[0;36mread_url\u001b[1;34m(url, url_idx, data)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mread_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mword_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwordList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;31m# TODO\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-0234e178a6d1>\u001b[0m in \u001b[0;36mwordList\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwordList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"html.parser\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(url, params, **kwargs)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'allow_redirects'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'get'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(method, url, **kwargs)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    531\u001b[0m         }\n\u001b[0;32m    532\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 533\u001b[1;33m         \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    534\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    535\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\sessions.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m         \u001b[1;31m# Send the request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 646\u001b[1;33m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\requests\\adapters.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    514\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mSSLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mConnectionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mClosedPoolError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mConnectionError\u001b[0m: HTTPConnectionPool(host='soave.isti.cnr.it', port=80): Max retries exceeded with url: /~silvestr/wp-content/uploads/2007/03/p63-baraglia.pdf (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000026B77A499E8>: Failed to establish a new connection: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond'))"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "#for url_index, url in enumerate(url_list, 1):\n",
    "    #read_url(url, url_index, data)\n",
    "for i in url_list:\n",
    "    read_url(i,1,data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "740eXy7pRryx"
   },
   "source": [
    "## 3. Tiền xử lý\n",
    "Loại bỏ các item trong data mà key là các stopword.\n",
    "\n",
    "**Ngữ liệu:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hC58K3Q3Rryy",
    "outputId": "99a20ea5-89c3-4d93-c74f-e43636b9b1cf"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "print(english_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cylo7trpRnun"
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Loại bỏ các key của biến data mà nằm trong danh sách english_stopwords\n",
    "list_keys=data.keys()\n",
    "for i in list(list_keys):\n",
    "    if i in english_stopwords:# kiểm tra xem key có trong english top w ko\n",
    "        data.pop(i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEoxNVHqRry2"
   },
   "source": [
    "## 4. Lưu trữ và biểu diễn dữ liệu\n",
    "Sử dụng pickle lưu lại data với tên file raw_data.\n",
    "### 4.1 Cơ sở dữ liệu giao tác:\n",
    "Thông thường, các cơ sở dữ liệu giao tác được lưu trong flat files (các tập phẳng) thay vì trong một hệ cơ sở dữ liệu. Các item là các số nguyên không âm, mỗi giao tác tương ứng với một dòng các số nguyên phân tách nhau bằng khoảng trắng.\n",
    "Ví dụ:\n",
    "\n",
    "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 \n",
    "\n",
    "30 31 32 \n",
    "\n",
    "33 34 35 \n",
    "\n",
    "36 37 38 39 40 41 42 43 44 45 46 \n",
    "\n",
    "38 39 47 48 \n",
    "\n",
    "38 39 48 49 50 51 52 53 54 55 56 57 58 \n",
    "\n",
    "32 41 59 60 61 62 \n",
    "\n",
    "3 39 48 \n",
    "\n",
    "63 64 65 66 67 68 \n",
    "\n",
    "32 69 \n",
    "\n",
    "48 70 71 72 \n",
    "\n",
    "39 73 74 75 76 77 78 79 \n",
    "\n",
    "36 38 39 41 48 79 80 81 \n",
    "\n",
    "82 83 84 \n",
    "\n",
    "41 85 86 87 88 \n",
    "\n",
    "39 48 89 90 91 92 93 94 95 96 97 98 99 100 101 \n",
    "\n",
    "36 38 39 48 89 \n",
    "\n",
    "39 41 102 103 104 105 106 107 108 \n",
    "\n",
    "38 39 41 109 110 \n",
    "\n",
    "39 111 112 113 114 115 116 117 118 \n",
    "\n",
    "119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 \n",
    "\n",
    "48 134 135 136 \n",
    "\n",
    "39 48 137 138 139 140 141 142 143 144 145 146 147 148 149 \n",
    "\n",
    "39 150 151 152 \n",
    "\n",
    "38 39 56 153 154 155 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4l--TVLEoN7R"
   },
   "outputs": [],
   "source": [
    "with open('raw_data', 'wb') as f:\n",
    "    pickle.dump(data,f)\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvUgw0VkRry3"
   },
   "source": [
    "### 4.2 Xuất dataset\n",
    "Lưu một cơ sở dữ liệu giao tác (transactional database) vào file t_data.txt: \n",
    "- Các item tương ứng với url_idx\n",
    "- Mỗi transaction tương ứng với một từ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZorK46LdSCfi"
   },
   "outputs": [],
   "source": [
    "with open('t_data.txt', 'w') as f:\n",
    "    for word, (url_list, freq) in data.items():\n",
    "        print(*url_list, file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OXVFoHiRry3"
   },
   "source": [
    "## 5. Truy vấn and, or, not\n",
    "Ví dụ: \n",
    "- Truy vấn `and` câu `web mining`: trả về đường dẫn tới các trang web có cả 2 từ web và từ mining. \n",
    "- Truy vấn `or` câu `web mining`: trả về đường dẫn tới các trang web có từ web hoặc từ mining.\n",
    "- Truy vấn `not` câu `web mining`: trả về đường dẫn tới các trang không có cả từ web và từ mining.\n",
    "\n",
    "*GỢI Ý: TÁCH CÂU TRUY VẤN THÀNH CÁC TỪ TƯƠNG TỰ PHƯƠNG PHÁP LÀM Ở LAB02.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "sybM0yLHRry6"
   },
   "outputs": [],
   "source": [
    "ret=[]\n",
    "def andRetrieval(ret, sentence):\n",
    "    '''Parameters\n",
    "    -----------------------\n",
    "    ret: url_list\n",
    "    sentence: query'''\n",
    "    # TODO\n",
    "    ### split sentence (separator ' ') into terms\n",
    "    ### find urls have all terms: urls\n",
    "    ### if len(ret)==0:  return urls\n",
    "    ### else update ret with urls: intersection of ret and urls \n",
    "    terms=sentence.split(\" \")# split query into terms\n",
    "    for j in url_list: # duyệt qua tất cả các url\n",
    "        flag=0\n",
    "        for i in terms:# duyệt qua tất cả các terms trong sentence \n",
    "            check=j.find(i)# tìm kiếm xem trong url có terms không\n",
    "            if(check==-1):# nếu không có \n",
    "                flag=0\n",
    "                break# thoát khỏi vòng lặp\n",
    "            else:\n",
    "                flag=1#đổi biến flag\n",
    "        if(flag==1):# nếu có tất cả các terms trong urls thì thêm url vào ret\n",
    "            ret.append(j)# thêm url có tất cả các terms vào ret\n",
    "        #nếu thoát khỏi vòng lặp kiểm tra len(ret=0)\n",
    "    if len(ret)==0:\n",
    "        return ret\n",
    "    else:\n",
    "        return ret\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "def orRetrieval(ret, sentence):\n",
    "    '''Parameters\n",
    "    -----------------------\n",
    "    ret: url_list\n",
    "    sentence: query'''\n",
    "    # TODO\n",
    "    ### split sentence (separator ' ') into terms\n",
    "    ### find urls have all terms: urls\n",
    "    ### find urls have at least 1 term: urls\n",
    "    ### update ret with urls: extend ret with urls\n",
    "    terms=sentence.split(\" \")# split query into terms\n",
    "    for i in url_list:\n",
    "        for j in terms:\n",
    "            check=i.find(j)# tìm trong urls xem có terms không\n",
    "            if(check!=-1):#nếu có\n",
    "                ret.append(i)# them urls vào res\n",
    "                break #thoát\n",
    "    return ret\n",
    "            \n",
    "            \n",
    "    \n",
    "\n",
    "def notRetrieval(ret, sentence):\n",
    "    '''Parameters\n",
    "    -----------------------\n",
    "    ret: url_list\n",
    "    sentence: query'''\n",
    "    # TODO\n",
    "    ### split sentence (separator ' ') into terms\n",
    "    ### find urls have at least 1 term: urls\n",
    "    ### update ret with urls: remove urls from ret \n",
    "    terms=sentence.split(\" \")# split query into terms\n",
    "    for j in url_list:# duyệt qua tất cả các url\n",
    "        flag=0\n",
    "        for i in terms:# duyệt qua tất cả các terms trong sentence \n",
    "            check=j.find(i)# tìm kiếm xem trong url có terms không\n",
    "            if(check!=-1):# nếu  có các term\n",
    "                flag=0\n",
    "                break# thoát khỏi vòng lặp\n",
    "            else:\n",
    "                flag=1#đổi biến flag\n",
    "        if(flag==1):# nếu  không có tất cả các terms trong urls thì thêm url vào ret\n",
    "            ret.append(j)# thêm url có tất cả các terms vào ret\n",
    "        \n",
    "    \n",
    "    return ret\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1hkp7ej3qxRQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " andretrieval\n",
      "https://archive.org/details/webminingapplica0000scim/page/282\n",
      "https://www.researchgate.net/profile/Magdalini_Eirinaki/publication/220169917_Web_mining_for_web_personalization/links/0912f51379b8daa82a000000.pdf\n",
      "http://webmining.spd.louisville.edu/wp-content/uploads/2014/05/Nasraoui_WebKDD03_web_recomm.pdf\n",
      "http://webmining.spd.louisville.edu/wp-content/uploads/2014/05/Nasraoui-IFSA-99-mining-web-access-logs.pdf\n",
      "http://webmining.spd.louisville.edu/wp-content/uploads/2014/05/FINAL-Nasraoui-WWW-Personalization.pdf\n",
      "https://archive.org/services/img/webminingapplica0000scim\n",
      "https://archive.org/details/webminingapplica0000scim\n",
      "https://archive.org/services/img/webminingapplica0000scim/full/pct:200/0/default.jpg\n",
      "https://twitter.com/intent/tweet?url=https://archive.org/details/webminingapplica0000scim&amp;via=internetarchive&amp;text=Web+mining+%3A+applications+and+techniques+%3A+Scime%2C+Anthony%2C+1952-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.facebook.com/sharer/sharer.php?u=https://archive.org/details/webminingapplica0000scim\n",
      "http://www.reddit.com/submit?url=https://archive.org/details/webminingapplica0000scim&amp;title=Web+mining+%3A+applications+and+techniques+%3A+Scime%2C+Anthony%2C+1952-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.tumblr.com/share/video?embed=%3Ciframe+width%3D%22640%22+height%3D%22480%22+frameborder%3D%220%22+allowfullscreen+src%3D%22https%3A%2F%2Farchive.org%2Fembed%2F%22+webkitallowfullscreen%3D%22true%22+mozallowfullscreen%3D%22true%22%26gt%3B%26lt%3B%2Fiframe%3E&amp;name=Web+mining+%3A+applications+and+techniques+%3A+Scime%2C+Anthony%2C+1952-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "http://www.pinterest.com/pin/create/button/?url=https://archive.org/details/webminingapplica0000scim&amp;description=Web+mining+%3A+applications+and+techniques+%3A+Scime%2C+Anthony%2C+1952-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://archive.org/details/webminingapplica0000scim&amp;subject=Web\n",
      "https://archive.org/embed/webminingapplica0000scim\n",
      " orretrieval\n",
      "https://en.wikipedia.org/wiki/Web_mining\n",
      "https://en.wikipedia.org/w/index.php?title=Web_mining&amp;action=edit\n",
      "https://en.wikipedia.org/w/index.php?title=Web_mining&amp;action=edit&amp;section=\n",
      "https://archive.org/details/webinformationsy00ngua\n",
      "https://archive.org/details/webinformationsy00ngua/page/n33\n",
      "https://archive.org/details/webminingapplica0000scim/page/282\n",
      "http://facweb.cs.depaul.edu/mobasher/classes/ect584/papers/cms-kais.pdf\n",
      "https://www.researchgate.net/profile/Magdalini_Eirinaki/publication/220169917_Web_mining_for_web_personalization/links/0912f51379b8daa82a000000.pdf\n",
      "http://facweb.cs.depaul.edu/mobasher/research/papers/widm01.pdf\n",
      "http://webmining.spd.louisville.edu/wp-content/uploads/2014/05/Nasraoui_WebKDD03_web_recomm.pdf\n",
      "http://webmining.spd.louisville.edu/wp-content/uploads/2014/05/Nasraoui-IFSA-99-mining-web-access-logs.pdf\n",
      "http://webmining.spd.louisville.edu/wp-content/uploads/2014/05/FINAL-Nasraoui-WWW-Personalization.pdf\n",
      "https://en.wikipedia.org/w/index.php?title=Web_mining&amp;oldid=1014859181\n",
      "https://en.wikipedia.org/w/index.php?title=Web_mining&amp;oldid=1014859181</a>\n",
      "https://es.wikipedia.org/wiki/Web_mining\n",
      "https://fr.wikipedia.org/wiki/Fouille_du_web\n",
      "https://pt.wikipedia.org/wiki/Minera%C3%A7%C3%A3o_da_web\n",
      "https://ru.wikipedia.org/wiki/Web_mining\n",
      "https://sk.wikipedia.org/wiki/Web_mining\n",
      "https://archive.org/services/img/webinformationsy00ngua\n",
      "https://archive.org/services/img/webinformationsy00ngua/full/pct:200/0/default.jpg\n",
      "https://archive.org/web/\n",
      "https://twitter.com/intent/tweet?url=https://archive.org/details/webinformationsy00ngua&amp;via=internetarchive&amp;text=Web+information+systems+engineering+%3A+WISE+2005%2C+6th+International+Conference+on+Web+Information+Systems+Engineering%2C+New+York%2C+NY%2C+USA%2C+November+20-22%2C+2005+%3A+proceedings+%3A+International+Conference+on+Web+Information+Systems+Engineering+%286th+%3A+2005+%3A+New+York%2C+N.Y.%29+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.facebook.com/sharer/sharer.php?u=https://archive.org/details/webinformationsy00ngua\n",
      "http://www.reddit.com/submit?url=https://archive.org/details/webinformationsy00ngua&amp;title=Web+information+systems+engineering+%3A+WISE+2005%2C+6th+International+Conference+on+Web+Information+Systems+Engineering%2C+New+York%2C+NY%2C+USA%2C+November+20-22%2C+2005+%3A+proceedings+%3A+International+Conference+on+Web+Information+Systems+Engineering+%286th+%3A+2005+%3A+New+York%2C+N.Y.%29+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.tumblr.com/share/video?embed=%3Ciframe+width%3D%22640%22+height%3D%22480%22+frameborder%3D%220%22+allowfullscreen+src%3D%22https%3A%2F%2Farchive.org%2Fembed%2F%22+webkitallowfullscreen%3D%22true%22+mozallowfullscreen%3D%22true%22%26gt%3B%26lt%3B%2Fiframe%3E&amp;name=Web+information+systems+engineering+%3A+WISE+2005%2C+6th+International+Conference+on+Web+Information+Systems+Engineering%2C+New+York%2C+NY%2C+USA%2C+November+20-22%2C+2005+%3A+proceedings+%3A+International+Conference+on+Web+Information+Systems+Engineering+%286th+%3A+2005+%3A+New+York%2C+N.Y.%29+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "http://www.pinterest.com/pin/create/button/?url=https://archive.org/details/webinformationsy00ngua&amp;description=Web+information+systems+engineering+%3A+WISE+2005%2C+6th+International+Conference+on+Web+Information+Systems+Engineering%2C+New+York%2C+NY%2C+USA%2C+November+20-22%2C+2005+%3A+proceedings+%3A+International+Conference+on+Web+Information+Systems+Engineering+%286th+%3A+2005+%3A+New+York%2C+N.Y.%29+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://archive.org/details/webinformationsy00ngua&amp;subject=Web\n",
      "https://archive.org/embed/webinformationsy00ngua\n",
      "https://twitter.com/intent/tweet?url=https://archive.org/details/electroniccommer00bauk_698&amp;via=internetarchive&amp;text=Electronic+commerce+and+web+technologies+%3A+first+international+conference%2C+EC-Web+2000%2C+London%2C+UK%2C+September+4-6%2C+2000+proceedings+%3A+Bauknecht%2C+Kurt%2C+1936-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "http://www.reddit.com/submit?url=https://archive.org/details/electroniccommer00bauk_698&amp;title=Electronic+commerce+and+web+technologies+%3A+first+international+conference%2C+EC-Web+2000%2C+London%2C+UK%2C+September+4-6%2C+2000+proceedings+%3A+Bauknecht%2C+Kurt%2C+1936-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.tumblr.com/share/video?embed=%3Ciframe+width%3D%22640%22+height%3D%22480%22+frameborder%3D%220%22+allowfullscreen+src%3D%22https%3A%2F%2Farchive.org%2Fembed%2F%22+webkitallowfullscreen%3D%22true%22+mozallowfullscreen%3D%22true%22%26gt%3B%26lt%3B%2Fiframe%3E&amp;name=Electronic+commerce+and+web+technologies+%3A+first+international+conference%2C+EC-Web+2000%2C+London%2C+UK%2C+September+4-6%2C+2000+proceedings+%3A+Bauknecht%2C+Kurt%2C+1936-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "http://www.pinterest.com/pin/create/button/?url=https://archive.org/details/electroniccommer00bauk_698&amp;description=Electronic+commerce+and+web+technologies+%3A+first+international+conference%2C+EC-Web+2000%2C+London%2C+UK%2C+September+4-6%2C+2000+proceedings+%3A+Bauknecht%2C+Kurt%2C+1936-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.betterworldbooks.com/product/detail/electronic-commerce-and-web-technologies-first-international-conference-ec-web-2000-london-uk-3540679812\n",
      "https://archive.org/services/img/webminingapplica0000scim\n",
      "https://archive.org/details/webminingapplica0000scim\n",
      "https://archive.org/services/img/webminingapplica0000scim/full/pct:200/0/default.jpg\n",
      "https://twitter.com/intent/tweet?url=https://archive.org/details/webminingapplica0000scim&amp;via=internetarchive&amp;text=Web+mining+%3A+applications+and+techniques+%3A+Scime%2C+Anthony%2C+1952-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.facebook.com/sharer/sharer.php?u=https://archive.org/details/webminingapplica0000scim\n",
      "http://www.reddit.com/submit?url=https://archive.org/details/webminingapplica0000scim&amp;title=Web+mining+%3A+applications+and+techniques+%3A+Scime%2C+Anthony%2C+1952-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://www.tumblr.com/share/video?embed=%3Ciframe+width%3D%22640%22+height%3D%22480%22+frameborder%3D%220%22+allowfullscreen+src%3D%22https%3A%2F%2Farchive.org%2Fembed%2F%22+webkitallowfullscreen%3D%22true%22+mozallowfullscreen%3D%22true%22%26gt%3B%26lt%3B%2Fiframe%3E&amp;name=Web+mining+%3A+applications+and+techniques+%3A+Scime%2C+Anthony%2C+1952-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "http://www.pinterest.com/pin/create/button/?url=https://archive.org/details/webminingapplica0000scim&amp;description=Web+mining+%3A+applications+and+techniques+%3A+Scime%2C+Anthony%2C+1952-+%3A+Free+Download%2C+Borrow%2C+and+Streaming+%3A+Internet+Archive\n",
      "https://archive.org/details/webminingapplica0000scim&amp;subject=Web\n",
      "https://archive.org/embed/webminingapplica0000scim\n",
      "https://my.unisa.edu.au/public/staffweb/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "res=andRetrieval([], 'web mining')\n",
    "print(\" andretrieval\")\n",
    "for i in res:\n",
    "    print(i)\n",
    "orres=orRetrieval([], 'web mining')\n",
    "print(\" orretrieval\")\n",
    "for i in orres:\n",
    "    print(i)\n",
    "notres=notRetrieval(url_list, 'web mining')\n",
    "print(\"notretrieval\")\n",
    "for i in notres:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of Lab03-WebCrawler.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
